{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "Su9UaTllPPyT",
      "metadata": {
        "id": "Su9UaTllPPyT"
      },
      "source": [
        "## Install Vertex AI SDK for Python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sp5rXuilbYyz1ue2BFuSmJle",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 810
        },
        "executionInfo": {
          "elapsed": 22432,
          "status": "ok",
          "timestamp": 1715273248418,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -360
        },
        "id": "sp5rXuilbYyz1ue2BFuSmJle",
        "outputId": "b9cce133-1335-4040-f93d-af7d17af8c87",
        "tags": []
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade --user google-cloud-aiplatform"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mO8cqwwwRIJv",
      "metadata": {
        "id": "mO8cqwwwRIJv"
      },
      "source": [
        "## Authenticate your notebook environment ( Colab only )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BWflD-lzRFgC",
      "metadata": {
        "id": "BWflD-lzRFgC"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "# Additional authentication is required for Google Colab\n",
        "if \"google.colab\" in sys.modules:\n",
        "    # Authenticate user to Google Cloud\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Ef3YjVSsRp9Q",
      "metadata": {
        "id": "Ef3YjVSsRp9Q"
      },
      "source": [
        "## Set Google Cloud project information and initialize Vertex AI SDK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "G1MCN16ZRFR3",
      "metadata": {
        "id": "G1MCN16ZRFR3"
      },
      "outputs": [],
      "source": [
        "# Define project information\n",
        "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
        "LOCATION = \"[your-region]\"  # @param {type:\"string\"}\n",
        "\n",
        "# Initialize Vertex AI\n",
        "import vertexai\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KOBAtIV3R8mY",
      "metadata": {
        "id": "KOBAtIV3R8mY"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lXlozq1mQThR",
      "metadata": {
        "executionInfo": {
          "elapsed": 3,
          "status": "ok",
          "timestamp": 1715273479392,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -360
        },
        "id": "lXlozq1mQThR"
      },
      "outputs": [],
      "source": [
        "from vertexai.preview.generative_models import (\n",
        "    GenerationConfig,\n",
        "    GenerativeModel,\n",
        "    HarmCategory,\n",
        "    HarmBlockThreshold,\n",
        "    Image,\n",
        "    Part\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Pyza6kJuSCg_",
      "metadata": {
        "id": "Pyza6kJuSCg_"
      },
      "source": [
        "## Use the Gemini 1.0 Pro model\n",
        "\n",
        "The Gemini 1.0 Pro (`gemini-1.0-pro`) model is designed to handle natural language tasks, multi-turn text and code chat, and code generation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "teZPcNCISLkQ",
      "metadata": {
        "id": "teZPcNCISLkQ"
      },
      "source": [
        "## Load the Gemini 1.0 Pro model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kUB8nEGhQXMH",
      "metadata": {
        "executionInfo": {
          "elapsed": 1645,
          "status": "ok",
          "timestamp": 1715273795751,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -360
        },
        "id": "kUB8nEGhQXMH"
      },
      "outputs": [],
      "source": [
        "model = GenerativeModel(\"gemini-1.0-pro\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "soDP_1kmSTSn",
      "metadata": {
        "id": "soDP_1kmSTSn"
      },
      "source": [
        "## Generate text from text prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xuwrxROoSESn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 5368,
          "status": "ok",
          "timestamp": 1715273833203,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -360
        },
        "id": "xuwrxROoSESn",
        "outputId": "5049bb6c-2e12-4f75-8a3b-fb9a261f7cf3"
      },
      "outputs": [],
      "source": [
        "responses = model.generate_content(\"Why is the sky blue?\", stream=True)\n",
        "\n",
        "for response in responses:\n",
        "    print(response.text, end=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fzYuVSYkSoV5",
      "metadata": {
        "id": "fzYuVSYkSoV5"
      },
      "source": [
        "#### Try your own prompts\n",
        "\n",
        "- What are the biggest challenges facing the healthcare industry?\n",
        "- What are the latest developments in the automotive industry?\n",
        "- What are the biggest opportunities in retail industry?\n",
        "- (Try your own prompts!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yhtHW2wySENe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 1457,
          "status": "ok",
          "timestamp": 1715273974082,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -360
        },
        "id": "yhtHW2wySENe",
        "outputId": "82630fa6-4d02-45f2-8aff-32a1335c2db5"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"Create a numbered list of 10 items. Each item in the list should be a trend in the tech industry.\n",
        "\n",
        "Each trend should be less than 5 words.\"\"\"  # try your own prompt\n",
        "\n",
        "responses = model.generate_content(prompt, stream=True)\n",
        "\n",
        "for response in responses:\n",
        "    print(response.text, end=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lmoUexYKTFmj",
      "metadata": {
        "id": "lmoUexYKTFmj"
      },
      "source": [
        "## Model parameters\n",
        "\n",
        "Every prompt you send to the model includes parameter values that control how the model generates a response. The model can generate different results for different parameter values. You can experiment with different model parameters to see how the results change."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "q4C71eAFSEK3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 4657,
          "status": "ok",
          "timestamp": 1715274333331,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -360
        },
        "id": "q4C71eAFSEK3",
        "outputId": "dabb91d0-4224-42e2-d9b9-82eca79539ad"
      },
      "outputs": [],
      "source": [
        "generation_config = GenerationConfig(\n",
        "    temperature=0.9,\n",
        "    top_p=1.0,\n",
        "    top_k=32,\n",
        "    candidate_count=1,\n",
        "    max_output_tokens=8192,\n",
        ")\n",
        "\n",
        "responses = model.generate_content(\n",
        "    \"Why is the sky blue?\",\n",
        "    generation_config=generation_config,\n",
        "    stream=True,\n",
        ")\n",
        "\n",
        "for response in responses:\n",
        "    print(response.text, end=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Q0UJFWjSTqFA",
      "metadata": {
        "id": "Q0UJFWjSTqFA"
      },
      "source": [
        "## Test chat prompts\n",
        "\n",
        "The Gemini 1.0 Pro model supports natural multi-turn conversations and is ideal for text tasks that require back-and-forth interactions. The following examples show how the model responds during a multi-turn conversation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GhB5CcPrTK6g",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 7663,
          "status": "ok",
          "timestamp": 1715274392056,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -360
        },
        "id": "GhB5CcPrTK6g",
        "outputId": "dc211704-3225-4c43-90e7-563706e18d82"
      },
      "outputs": [],
      "source": [
        "chat = model.start_chat()\n",
        "\n",
        "prompt = \"\"\"My name is Bappy. You are my personal assistant. My favorite movies are Lord of the Rings and Hobbit.\n",
        "\n",
        "Suggest another movie I might like.\n",
        "\"\"\"\n",
        "\n",
        "responses = chat.send_message(prompt, stream=True)\n",
        "\n",
        "for response in responses:\n",
        "    print(response.text, end=\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "S3LGA9KUUBEx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 4021,
          "status": "ok",
          "timestamp": 1715274414465,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -360
        },
        "id": "S3LGA9KUUBEx",
        "outputId": "1ab71ea8-3f78-4823-ac08-153f948d5bfc"
      },
      "outputs": [],
      "source": [
        "prompt = \"Are my favorite movies based on a book series?\"\n",
        "\n",
        "responses = chat.send_message(prompt, stream=True)\n",
        "\n",
        "for response in responses:\n",
        "    print(response.text, end=\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "px-5Z66lUjFa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 6,
          "status": "ok",
          "timestamp": 1715274421164,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -360
        },
        "id": "px-5Z66lUjFa",
        "outputId": "3beda74e-7462-42a9-9327-8ed8aeba3ef8"
      },
      "outputs": [],
      "source": [
        "print(chat.history)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yyL2D64FUrv0",
      "metadata": {
        "id": "yyL2D64FUrv0"
      },
      "source": [
        "## Use the Gemini 1.0 Pro Vision model\n",
        "\n",
        "Gemini 1.0 Pro Vision (`gemini-1.0-pro-vision`) is a multimodal model that supports multimodal prompts. You can include text, image(s), and video in your prompt requests and get text or code responses.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0x70HpCvUygS",
      "metadata": {
        "id": "0x70HpCvUygS"
      },
      "source": [
        "## Load the Gemini 1.0 Pro Vision model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XmX0_rx4UjDI",
      "metadata": {
        "executionInfo": {
          "elapsed": 2,
          "status": "ok",
          "timestamp": 1715274470260,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -360
        },
        "id": "XmX0_rx4UjDI"
      },
      "outputs": [],
      "source": [
        "multimodal_model = GenerativeModel(\"gemini-1.0-pro-vision\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yjZxfjOFU4yI",
      "metadata": {
        "id": "yjZxfjOFU4yI"
      },
      "source": [
        "### Define helper functions\n",
        "\n",
        "Define helper functions to load and display images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "djWRgfLLUjAP",
      "metadata": {
        "executionInfo": {
          "elapsed": 754,
          "status": "ok",
          "timestamp": 1715274504481,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -360
        },
        "id": "djWRgfLLUjAP"
      },
      "outputs": [],
      "source": [
        "import http.client\n",
        "import typing\n",
        "import urllib.request\n",
        "\n",
        "import IPython.display\n",
        "from PIL import Image as PIL_Image\n",
        "from PIL import ImageOps as PIL_ImageOps\n",
        "\n",
        "\n",
        "def display_images(\n",
        "    images: typing.Iterable[Image],\n",
        "    max_width: int = 600,\n",
        "    max_height: int = 350,\n",
        ") -> None:\n",
        "    for image in images:\n",
        "        pil_image = typing.cast(PIL_Image.Image, image._pil_image)\n",
        "        if pil_image.mode != \"RGB\":\n",
        "            # RGB is supported by all Jupyter environments (e.g. RGBA is not yet)\n",
        "            pil_image = pil_image.convert(\"RGB\")\n",
        "        image_width, image_height = pil_image.size\n",
        "        if max_width < image_width or max_height < image_height:\n",
        "            # Resize to display a smaller notebook image\n",
        "            pil_image = PIL_ImageOps.contain(pil_image, (max_width, max_height))\n",
        "        IPython.display.display(pil_image)\n",
        "\n",
        "\n",
        "def get_image_bytes_from_url(image_url: str) -> bytes:\n",
        "    with urllib.request.urlopen(image_url) as response:\n",
        "        response = typing.cast(http.client.HTTPResponse, response)\n",
        "        image_bytes = response.read()\n",
        "    return image_bytes\n",
        "\n",
        "\n",
        "def load_image_from_url(image_url: str) -> Image:\n",
        "    image_bytes = get_image_bytes_from_url(image_url)\n",
        "    return Image.from_bytes(image_bytes)\n",
        "\n",
        "\n",
        "def get_url_from_gcs(gcs_uri: str) -> str:\n",
        "    # converts gcs uri to url for image display.\n",
        "    url = \"https://storage.googleapis.com/\" + gcs_uri.replace(\"gs://\", \"\").replace(\n",
        "        \" \", \"%20\"\n",
        "    )\n",
        "    return url\n",
        "\n",
        "\n",
        "def print_multimodal_prompt(contents: list):\n",
        "    \"\"\"\n",
        "    Given contents that would be sent to Gemini,\n",
        "    output the full multimodal prompt for ease of readability.\n",
        "    \"\"\"\n",
        "    for content in contents:\n",
        "        if isinstance(content, Image):\n",
        "            display_images([content])\n",
        "        elif isinstance(content, Part):\n",
        "            url = get_url_from_gcs(content.file_data.file_uri)\n",
        "            IPython.display.display(load_image_from_url(url))\n",
        "        else:\n",
        "            print(content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hZ1BOIKkVCEI",
      "metadata": {
        "id": "hZ1BOIKkVCEI"
      },
      "source": [
        "### Generate text from local image and text\n",
        "\n",
        "Use the `Image.load_from_file` method to load a local file as the image to generate text for.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QU-NSi-bUi9n",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "executionInfo": {
          "elapsed": 8156,
          "status": "ok",
          "timestamp": 1715274567716,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -360
        },
        "id": "QU-NSi-bUi9n",
        "outputId": "d79f10c1-e82c-4aa4-eb2b-40d9471686a2"
      },
      "outputs": [],
      "source": [
        "# Download an image from Google Cloud Storage\n",
        "! gsutil cp \"gs://cloud-samples-data/generative-ai/image/320px-Felis_catus-cat_on_snow.jpg\" ./image.jpg\n",
        "\n",
        "# Load from local file\n",
        "image = Image.load_from_file(\"image.jpg\")\n",
        "\n",
        "# Prepare contents\n",
        "prompt = \"Describe this image?\"\n",
        "contents = [image, prompt]\n",
        "\n",
        "responses = multimodal_model.generate_content(contents, stream=True)\n",
        "\n",
        "print(\"-------Prompt--------\")\n",
        "print_multimodal_prompt(contents)\n",
        "\n",
        "print(\"\\n-------Response--------\")\n",
        "for response in responses:\n",
        "    print(response.text, end=\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7YedKprlVKjH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "executionInfo": {
          "elapsed": 2560,
          "status": "ok",
          "timestamp": 1715274668838,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -360
        },
        "id": "7YedKprlVKjH",
        "outputId": "13049057-e960-4883-bb3d-b3918161e944"
      },
      "outputs": [],
      "source": [
        "# Load image from Cloud Storage URI\n",
        "gcs_uri = \"gs://cloud-samples-data/generative-ai/image/boats.jpeg\"\n",
        "\n",
        "# Prepare contents\n",
        "image = Part.from_uri(gcs_uri, mime_type=\"image/jpeg\")\n",
        "prompt = \"Describe the scene?\"\n",
        "contents = [image, prompt]\n",
        "\n",
        "responses = multimodal_model.generate_content(contents, stream=True)\n",
        "\n",
        "print(\"-------Prompt--------\")\n",
        "print_multimodal_prompt(contents)\n",
        "\n",
        "print(\"\\n-------Response--------\")\n",
        "for response in responses:\n",
        "    print(response.text, end=\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "G-zspeLXVkgP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "executionInfo": {
          "elapsed": 2116,
          "status": "ok",
          "timestamp": 1715274700886,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -360
        },
        "id": "G-zspeLXVkgP",
        "outputId": "0aaf6c4e-8dbc-4eec-c734-0c85529f5ffe"
      },
      "outputs": [],
      "source": [
        "# Load image from Cloud Storage URI\n",
        "image_url = (\n",
        "    \"https://storage.googleapis.com/cloud-samples-data/generative-ai/image/boats.jpeg\"\n",
        ")\n",
        "image = load_image_from_url(image_url)  # convert to bytes\n",
        "\n",
        "# Prepare contents\n",
        "prompt = \"Describe the scene?\"\n",
        "contents = [image, prompt]\n",
        "\n",
        "responses = multimodal_model.generate_content(contents, stream=True)\n",
        "\n",
        "print(\"-------Prompt--------\")\n",
        "print_multimodal_prompt(contents)\n",
        "\n",
        "print(\"\\n-------Response--------\")\n",
        "for response in responses:\n",
        "    print(response.text, end=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Ow-TcQjvVwu4",
      "metadata": {
        "id": "Ow-TcQjvVwu4"
      },
      "source": [
        "## Combining multiple images and text prompts for few-shot prompting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YM9XzU7XVsXB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "executionInfo": {
          "elapsed": 1980,
          "status": "ok",
          "timestamp": 1715274790101,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -360
        },
        "id": "YM9XzU7XVsXB",
        "outputId": "d49b8a51-3eb7-4a19-ecdc-2d0901607a6e"
      },
      "outputs": [],
      "source": [
        "# Load images from Cloud Storage URI\n",
        "image1_url = \"https://storage.googleapis.com/github-repo/img/gemini/intro/landmark1.jpg\"\n",
        "image2_url = \"https://storage.googleapis.com/github-repo/img/gemini/intro/landmark2.jpg\"\n",
        "image3_url = \"https://storage.googleapis.com/github-repo/img/gemini/intro/landmark3.jpg\"\n",
        "image1 = load_image_from_url(image1_url)\n",
        "image2 = load_image_from_url(image2_url)\n",
        "image3 = load_image_from_url(image3_url)\n",
        "\n",
        "# Prepare prompts\n",
        "prompt1 = \"\"\"{\"city\": \"London\", \"Landmark:\", \"Big Ben\"}\"\"\"\n",
        "prompt2 = \"\"\"{\"city\": \"Paris\", \"Landmark:\", \"Eiffel Tower\"}\"\"\"\n",
        "\n",
        "# Prepare contents\n",
        "contents = [image1, prompt1, image2, prompt2, image3]\n",
        "\n",
        "responses = multimodal_model.generate_content(contents, stream=True)\n",
        "\n",
        "print(\"-------Prompt--------\")\n",
        "print_multimodal_prompt(contents)\n",
        "\n",
        "print(\"\\n-------Response--------\")\n",
        "for response in responses:\n",
        "    print(response.text, end=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fYtEag8bWMJh",
      "metadata": {
        "id": "fYtEag8bWMJh"
      },
      "source": [
        "### Generate text from a video file\n",
        "\n",
        "Specify the Cloud Storage URI of the video to include in the prompt. The bucket that stores the file must be in the same Google Cloud project that's sending the request. You must also specify the `mime_type` field. The supported MIME type for video includes `video/mp4`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "S96Q96ehWCHg",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "executionInfo": {
          "elapsed": 10,
          "status": "ok",
          "timestamp": 1715274846215,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -360
        },
        "id": "S96Q96ehWCHg",
        "outputId": "b9b6c355-7f0d-48c8-976f-2f889d348ff0"
      },
      "outputs": [],
      "source": [
        "file_path = \"github-repo/img/gemini/multimodality_usecases_overview/pixel8.mp4\"\n",
        "video_uri = f\"gs://{file_path}\"\n",
        "video_url = f\"https://storage.googleapis.com/{file_path}\"\n",
        "\n",
        "IPython.display.Video(video_url, width=450)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tcWlHPF_WQuv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 5423,
          "status": "ok",
          "timestamp": 1715274875661,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -360
        },
        "id": "tcWlHPF_WQuv",
        "outputId": "9e8cf90f-eea8-4037-9b34-53ff49cc641a"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"\n",
        "Answer the following questions using the video only:\n",
        "What is the profession of the main person?\n",
        "What are the main features of the phone highlighted?\n",
        "Which city was this recorded in?\n",
        "Provide the answer JSON.\n",
        "\"\"\"\n",
        "\n",
        "video = Part.from_uri(video_uri, mime_type=\"video/mp4\")\n",
        "contents = [prompt, video]\n",
        "\n",
        "responses = multimodal_model.generate_content(contents, stream=True)\n",
        "\n",
        "for response in responses:\n",
        "    print(response.text, end=\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SWqUjjMMWWfH",
      "metadata": {
        "id": "SWqUjjMMWWfH"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "colab0 (May 9, 2024, 10:42:16 PM)",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
