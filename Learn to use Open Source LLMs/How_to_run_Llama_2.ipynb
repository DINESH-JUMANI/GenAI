{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4bKQIsIq-d8y"
   },
   "source": [
    "#**Llama 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PnV5UC7A2vBZ"
   },
   "source": [
    "The Llama 2 is a collection of pretrained and fine-tuned generative text models, ranging from 7 billion to 70 billion parameters, designed for dialogue use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AC41zK5l3Abp"
   },
   "source": [
    " It outperforms open-source chat models on most benchmarks and is on par with popular closed-source models in human evaluations for helpfulness and safety."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4nobX9E83PjQ"
   },
   "source": [
    "[Llama 2 13B-chat](https://huggingface.co/meta-llama/Llama-2-13b-chat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0K4QuEDH4CbY"
   },
   "source": [
    "`llama.cpp`'s objective is to run the LLaMA model with 4-bit integer quantization on MacBook. It is a plain C/C++ implementation optimized for Apple silicon and x86 architectures, supporting various integer quantization and BLAS libraries. Originally a web chat example, it now serves as a development playground for ggml library features.\n",
    "\n",
    "`GGML`, a C library for machine learning, facilitates the distribution of large language models (LLMs). It utilizes quantization to enable efficient LLM execution on consumer hardware. GGML files contain binary-encoded data, including version number, hyperparameters, vocabulary, and weights. The vocabulary comprises tokens for language generation, while the weights determine the LLM's size. Quantization reduces precision to optimize resource usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3YC846SH5DOK"
   },
   "source": [
    "#  Quantized Models from the Hugging Face Community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0TD82wis5LGA"
   },
   "source": [
    "The Hugging Face community provides quantized models, which allow us to efficiently and effectively utilize the model on the T4 GPU. It is important to consult reliable sources before using any model.\n",
    "\n",
    "There are several variations available, but the ones that interest us are based on the GGLM library.\n",
    "\n",
    "We can see the different variations that Llama-2-13B-GGML has [here](https://huggingface.co/models?search=llama%202%20ggml).\n",
    "\n",
    "\n",
    "\n",
    "In this case, we will use the model called [Llama-2-13B-chat-GGML](https://huggingface.co/TheBloke/Llama-2-13B-chat-GGML)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YQZBmz7I5neU"
   },
   "source": [
    "#**1: Install All the Required Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1702896492324,
     "user": {
      "displayName": "colab0 ineuron",
      "userId": "16851312232179065356"
     },
     "user_tz": -360
    },
    "id": "v_dliwERb6Uh",
    "outputId": "f83fa79b-e26a-4daf-fee3-c0e47d91b9a3"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 128919,
     "status": "ok",
     "timestamp": 1702896628340,
     "user": {
      "displayName": "colab0 ineuron",
      "userId": "16851312232179065356"
     },
     "user_tz": -360
    },
    "id": "L0avf7xx2lcj",
    "outputId": "2e710f37-5e86-43bb-95bd-8bd3b35c5419"
   },
   "outputs": [],
   "source": [
    "# GPU llama-cpp-python\n",
    "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install llama-cpp-python==0.1.78 numpy==1.23.4 --force-reinstall --upgrade --no-cache-dir --verbose\n",
    "!pip install huggingface_hub\n",
    "!pip install llama-cpp-python==0.1.78\n",
    "!pip install numpy==1.23.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 410,
     "status": "ok",
     "timestamp": 1702896632386,
     "user": {
      "displayName": "colab0 ineuron",
      "userId": "16851312232179065356"
     },
     "user_tz": -360
    },
    "id": "qJ90LnMv54Y-"
   },
   "outputs": [],
   "source": [
    "model_name_or_path = \"TheBloke/Llama-2-13B-chat-GGML\"\n",
    "model_basename = \"llama-2-13b-chat.ggmlv3.q5_1.bin\" # the model is in bin format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6lOmpKB36RJh"
   },
   "source": [
    "#**2: Import All the Required Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1702896635638,
     "user": {
      "displayName": "colab0 ineuron",
      "userId": "16851312232179065356"
     },
     "user_tz": -360
    },
    "id": "Ak3ZtGjM6Wdp"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1031,
     "status": "ok",
     "timestamp": 1702896637049,
     "user": {
      "displayName": "colab0 ineuron",
      "userId": "16851312232179065356"
     },
     "user_tz": -360
    },
    "id": "85XOzmui6rGN"
   },
   "outputs": [],
   "source": [
    "from llama_cpp import Llama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "haAb9kNm6J9n"
   },
   "source": [
    "#**3: Download the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "61f728f470a64d7ba96c1ea7f534ea2a",
      "167854af5ba345c887b946413dc1eba6",
      "39a396c8527c49dc946b6ed6ff851d6b",
      "1920085e1ee740edbad6ef207fec327f",
      "ef7d2457fa03495198c01f461b61ae28",
      "532e060cd7a541f68db6a6e7b30eb1ea",
      "3b81fc9c8de84eff8b2083adfa7c9484",
      "0c1df7d59afa4b158bada2516c2c93fe",
      "78c35049b2494b7283d4e3841225aaee",
      "62981a143891468db7b7d8df19f9fb6d",
      "124cfafd45044f6dae7d237449cab2b4"
     ]
    },
    "executionInfo": {
     "elapsed": 83605,
     "status": "ok",
     "timestamp": 1702896721031,
     "user": {
      "displayName": "colab0 ineuron",
      "userId": "16851312232179065356"
     },
     "user_tz": -360
    },
    "id": "qBgdGV4b6MxG",
    "outputId": "9938970a-287b-485c-d5f1-693c411ddf7b"
   },
   "outputs": [],
   "source": [
    "model_path = hf_hub_download(repo_id=model_name_or_path, filename=model_basename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "executionInfo": {
     "elapsed": 429,
     "status": "ok",
     "timestamp": 1702896724416,
     "user": {
      "displayName": "colab0 ineuron",
      "userId": "16851312232179065356"
     },
     "user_tz": -360
    },
    "id": "kL3LF6pfE3HD",
    "outputId": "92e1bbf2-4017-4eab-f4d8-ea7b5afa57f6"
   },
   "outputs": [],
   "source": [
    "model_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQ6OYnI46kKq"
   },
   "source": [
    "#**4: Loading the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35383,
     "status": "ok",
     "timestamp": 1702896762025,
     "user": {
      "displayName": "colab0 ineuron",
      "userId": "16851312232179065356"
     },
     "user_tz": -360
    },
    "id": "irftToUj6aWt",
    "outputId": "61b67c86-fdc4-4c2c-9abe-239f9fa682e8"
   },
   "outputs": [],
   "source": [
    "# GPU\n",
    "lcpp_llm = None\n",
    "lcpp_llm = Llama(\n",
    "    model_path=model_path,\n",
    "    n_threads=2, # CPU cores\n",
    "    n_batch=512, # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.\n",
    "    n_gpu_layers=32 # Change this value based on your model and your GPU VRAM pool.\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 364,
     "status": "ok",
     "timestamp": 1702896766730,
     "user": {
      "displayName": "colab0 ineuron",
      "userId": "16851312232179065356"
     },
     "user_tz": -360
    },
    "id": "YG4Pylz662At",
    "outputId": "9f5adc1a-3181-412c-de9c-a268ce99f1a0"
   },
   "outputs": [],
   "source": [
    "# See the number of layers in GPU\n",
    "lcpp_llm.params.n_gpu_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iE-M307R6_pT"
   },
   "source": [
    "#**5: Create a Prompt Template**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 356,
     "status": "ok",
     "timestamp": 1702896773148,
     "user": {
      "displayName": "colab0 ineuron",
      "userId": "16851312232179065356"
     },
     "user_tz": -360
    },
    "id": "RfzwELMC7Dyg"
   },
   "outputs": [],
   "source": [
    "prompt = \"Write a linear regression code\"\n",
    "prompt_template=f'''SYSTEM: You are a helpful, respectful and honest assistant. Always answer as helpfully.\n",
    "\n",
    "USER: {prompt}\n",
    "\n",
    "ASSISTANT:\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aT8pg6zt7QzA"
   },
   "source": [
    "#**6: Generating the Response**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 109660,
     "status": "ok",
     "timestamp": 1702896986205,
     "user": {
      "displayName": "colab0 ineuron",
      "userId": "16851312232179065356"
     },
     "user_tz": -360
    },
    "id": "0aF0qWUJ7OPK",
    "outputId": "cd20446b-7724-4839-be2a-c00ea83f53ba"
   },
   "outputs": [],
   "source": [
    "response=lcpp_llm(prompt=prompt_template, max_tokens=256, temperature=0.5, top_p=0.95,\n",
    "                  repeat_penalty=1.2, top_k=150,\n",
    "                  echo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 414,
     "status": "ok",
     "timestamp": 1702896993349,
     "user": {
      "displayName": "colab0 ineuron",
      "userId": "16851312232179065356"
     },
     "user_tz": -360
    },
    "id": "jlJ1JgR68DDO",
    "outputId": "e678959c-96fe-4e46-b101-edf5f85a5139"
   },
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1702896995188,
     "user": {
      "displayName": "colab0 ineuron",
      "userId": "16851312232179065356"
     },
     "user_tz": -360
    },
    "id": "Qona58gX8oAn",
    "outputId": "3e977582-ccde-4ef6-d8ce-a3616d604faf"
   },
   "outputs": [],
   "source": [
    "print(response[\"choices\"][0][\"text\"])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0c1df7d59afa4b158bada2516c2c93fe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "124cfafd45044f6dae7d237449cab2b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "167854af5ba345c887b946413dc1eba6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_532e060cd7a541f68db6a6e7b30eb1ea",
      "placeholder": "​",
      "style": "IPY_MODEL_3b81fc9c8de84eff8b2083adfa7c9484",
      "value": "llama-2-13b-chat.ggmlv3.q5_1.bin: 100%"
     }
    },
    "1920085e1ee740edbad6ef207fec327f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_62981a143891468db7b7d8df19f9fb6d",
      "placeholder": "​",
      "style": "IPY_MODEL_124cfafd45044f6dae7d237449cab2b4",
      "value": " 9.76G/9.76G [01:23&lt;00:00, 107MB/s]"
     }
    },
    "39a396c8527c49dc946b6ed6ff851d6b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0c1df7d59afa4b158bada2516c2c93fe",
      "max": 9763701888,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_78c35049b2494b7283d4e3841225aaee",
      "value": 9763701888
     }
    },
    "3b81fc9c8de84eff8b2083adfa7c9484": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "532e060cd7a541f68db6a6e7b30eb1ea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "61f728f470a64d7ba96c1ea7f534ea2a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_167854af5ba345c887b946413dc1eba6",
       "IPY_MODEL_39a396c8527c49dc946b6ed6ff851d6b",
       "IPY_MODEL_1920085e1ee740edbad6ef207fec327f"
      ],
      "layout": "IPY_MODEL_ef7d2457fa03495198c01f461b61ae28"
     }
    },
    "62981a143891468db7b7d8df19f9fb6d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "78c35049b2494b7283d4e3841225aaee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ef7d2457fa03495198c01f461b61ae28": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
