{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63NDakO5x8MZ"
      },
      "source": [
        "https://openai.com/sitemap.xml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVzGbRsVYXfS"
      },
      "source": [
        "#**1: Install All the Required Packages**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xs5mGElXeRW",
        "outputId": "6454e2bd-4fe4-40d6-b147-237f725ec557"
      },
      "outputs": [],
      "source": [
        "!pip -q install langchain langchain-community\n",
        "!pip -q install pypdf\n",
        "!pip -q install sentence_transformers\n",
        "!pip install openai\n",
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wTAq_eEdYXJ",
        "outputId": "c174a53d-216d-4849-ef6e-320fbd38c2dd"
      },
      "outputs": [],
      "source": [
        "!pip install tokenizers\n",
        "!pip install faiss-cpu\n",
        "!pip -q install unstructured"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SHyZ27I3Wmz",
        "outputId": "bd5e8a24-58a6-43e7-8ed4-312c8d48cab7"
      },
      "outputs": [],
      "source": [
        "!pip install numpy==1.24.4\n",
        "!pip install nltk==3.9.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmOAmLPKaBxX"
      },
      "source": [
        "#**2: Import All the Required Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqJ9GkdXZ0qm",
        "outputId": "8ef80812-e463-4f5e-b715-1557736e9396"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import torch\n",
        "import textwrap\n",
        "from langchain.document_loaders import UnstructuredURLLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains import RetrievalQAWithSourcesChain\n",
        "from langchain.embeddings import HuggingFaceEmbeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaR-PGkn-GlD",
        "outputId": "fc90da59-960b-4575-c366-43fb0523194b"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGm8wNIslUpw"
      },
      "source": [
        "#Create an Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2YBjadKlXd1"
      },
      "outputs": [],
      "source": [
        "os.environ['OPENAI_API_KEY'] = \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XtIoO7kayKZ"
      },
      "source": [
        "#**3: Pass the URLs and extract the data from these URLs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5zz-5MxbavYJ"
      },
      "outputs": [],
      "source": [
        "URLs=[\n",
        "    'https://blog.gopenai.com/paper-review-llama-2-open-foundation-and-fine-tuned-chat-models-23e539522acb',\n",
        "    'https://www.mosaicml.com/blog/mpt-7b',\n",
        "    'https://stability.ai/blog/stability-ai-launches-the-first-of-its-stablelm-suite-of-language-models',\n",
        "    'https://lmsys.org/blog/2023-03-30-vicuna/'\n",
        "\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMwp2mEHbjfI"
      },
      "outputs": [],
      "source": [
        "loaders = UnstructuredURLLoader(urls=URLs)\n",
        "data = loaders.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieqoWS2wbv0g",
        "outputId": "bc26c65b-7b32-4d51-b6ad-41ffb7ecd39b"
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQp4MaDzeC3g",
        "outputId": "02540ad9-b477-4ede-de1c-2fd5565f863d"
      },
      "outputs": [],
      "source": [
        "len(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hZXVlFqdwRv"
      },
      "source": [
        "#**4: Split the Text into Chunks**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DihTE_ob_zL"
      },
      "outputs": [],
      "source": [
        "text_splitter=CharacterTextSplitter(separator='\\n',\n",
        "                                    chunk_size=1000,\n",
        "                                    chunk_overlap=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fpk8mrzjeH17"
      },
      "outputs": [],
      "source": [
        "text_chunks=text_splitter.split_documents(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-l41qDAeNSf",
        "outputId": "3b23b350-3ff7-430e-8c2c-e4333b9cf6a3"
      },
      "outputs": [],
      "source": [
        "len(text_chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZjRHBnoeQ2R",
        "outputId": "93820a39-b34d-410f-ba31-a58a36e06d3e"
      },
      "outputs": [],
      "source": [
        "text_chunks[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSSE72OYeqCi",
        "outputId": "f83486e9-e282-469f-b95f-014638d16164"
      },
      "outputs": [],
      "source": [
        "text_chunks[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zb9LQ20e4Qs",
        "outputId": "938ec423-cee1-40a4-eb31-79c0532abfee"
      },
      "outputs": [],
      "source": [
        "text_chunks[2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRzFp91Wfb5d"
      },
      "source": [
        "#**5: Download the OpenAI Embeddings or Hugging Face Embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbpaRosM8Oud",
        "outputId": "a37f9730-04a5-42da-8a01-5f2c97c65486"
      },
      "outputs": [],
      "source": [
        "embeddings = OpenAIEmbeddings()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHNvev2k-V4D",
        "outputId": "d9b279d0-78ed-423e-dbdc-efc4a63f5732"
      },
      "outputs": [],
      "source": [
        "embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JTIYLHPUMtN",
        "outputId": "62a45bb3-b133-407b-91e7-56c31764df13"
      },
      "outputs": [],
      "source": [
        "query_result = embeddings.embed_query(\"Hello world\")\n",
        "len(query_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7UG7kM0hrtg"
      },
      "source": [
        "#**06: Convert the Text Chunks into Embeddings and Create a Knowledge Base**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3iG2iA-4hzIX"
      },
      "outputs": [],
      "source": [
        "vectorstore=FAISS.from_documents(text_chunks, embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7V8N04XjAdT"
      },
      "source": [
        "#**07: Create a Large Language Model (LLM) Wrapper**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmbUqPijjG3C",
        "outputId": "40157aa6-dab1-49d9-dbc8-d654e4b0b90c"
      },
      "outputs": [],
      "source": [
        "llm=ChatOpenAI()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSKa8emUsmhW",
        "outputId": "072a6791-d0af-4327-f1da-a34d23e9233a"
      },
      "outputs": [],
      "source": [
        "llm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "yDmBlmEDCG62",
        "outputId": "6d04fbba-7123-42f2-948f-0d8f904dd117"
      },
      "outputs": [],
      "source": [
        "llm.predict(\"Please provide a concise summary of the Book Harry Potter\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzgC6Z6wjpXC"
      },
      "source": [
        "#**08: Initialize the Retrieval QA with Source Chain**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8OITqbQgjvAj"
      },
      "outputs": [],
      "source": [
        "chain = RetrievalQAWithSourcesChain.from_llm(llm=llm, retriever=vectorstore.as_retriever())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhTOLCIGl3Os",
        "outputId": "01dd820c-d51c-49b1-9532-8455897b2eaf"
      },
      "outputs": [],
      "source": [
        "result=chain({\"question\": \"How good is Vicuna?\"}, return_only_outputs=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0ioHtqtBY7Ec",
        "outputId": "3002c704-ff60-4f49-fe73-8406458f78f4"
      },
      "outputs": [],
      "source": [
        "result['answer']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "meUipuOuGPff"
      },
      "outputs": [],
      "source": [
        "wrapped_text = textwrap.fill(result['answer'], width=500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "gy0zm_HDpxSg",
        "outputId": "c89fd5fb-91c2-418d-f795-71052ccf5eac"
      },
      "outputs": [],
      "source": [
        "wrapped_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ibpSu9GeZ0ED"
      },
      "outputs": [],
      "source": [
        "result=chain({\"question\": \"How does Llama 2 outperforms other models\"}, return_only_outputs=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "Yorw-ocya_ac",
        "outputId": "4bab8f6d-9150-4182-e64a-a3a358d14fba"
      },
      "outputs": [],
      "source": [
        "result['answer']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3AeyflGrSF9"
      },
      "outputs": [],
      "source": [
        "wrapped_text = textwrap.fill(result['answer'], width=500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "6NGE0JP5rTyu",
        "outputId": "dc07896d-21dc-4ba2-9678-f64f293eb9a9"
      },
      "outputs": [],
      "source": [
        "wrapped_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32qmjjbja4fW"
      },
      "outputs": [],
      "source": [
        "result=chain({\"question\": \"What is is stableLM?\"}, return_only_outputs=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "lTrdGoL7a9Ur",
        "outputId": "4886ba03-729c-43ef-e521-42e7dbb7f029"
      },
      "outputs": [],
      "source": [
        "result['answer']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3uB48-lmrdgF"
      },
      "outputs": [],
      "source": [
        "wrapped_text = textwrap.fill(result['answer'], width=500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "1EV_zfRFreap",
        "outputId": "137ba366-5079-4995-90bf-d32dfdb67117"
      },
      "outputs": [],
      "source": [
        "wrapped_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rFOT5g9TE7ws"
      },
      "outputs": [],
      "source": [
        "result=chain({\"question\": \"Can you please share some details about MPT-7b Model\"}, return_only_outputs=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "mH-s6NSuZcfr",
        "outputId": "803a9e22-a3a9-47a9-8478-12d6faba001a"
      },
      "outputs": [],
      "source": [
        "result['answer']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WwngqtcCDu9k"
      },
      "outputs": [],
      "source": [
        "wrapped_text = textwrap.fill(result['answer'], width=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "WtC9OJDHefg2",
        "outputId": "75390806-e569-4151-e1b9-df7dbb69f4d5"
      },
      "outputs": [],
      "source": [
        "wrapped_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "ffPUXfwKkLvH",
        "outputId": "5f5a0b6d-6894-4830-f0e9-e4bb5ca421c2"
      },
      "outputs": [],
      "source": [
        "while True:\n",
        "  query=input(f\"Prompt: \")\n",
        "  if query == 'exit':\n",
        "    print('Exiting')\n",
        "    sys.exit()\n",
        "  if query =='':\n",
        "    continue\n",
        "  result=chain({'question':query})\n",
        "  print(f\"Answer: \" +result[\"answer\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ab1lxX5WwXsJ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
